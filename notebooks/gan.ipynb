{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dados/nova_plataforma.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_remove = ['platform', 'recommended (1 partial; 2 complete)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(platform_remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_correlacao = df.corr()\n",
    "\n",
    "plt.figure(figsize=(16, 16), facecolor='#eaeaf2')\n",
    "\n",
    "ax = sns.heatmap(data=matriz_correlacao,\n",
    "                xticklabels=df.columns,\n",
    "                yticklabels=df.columns,\n",
    "                annot=True, \n",
    "                cmap='coolwarm',\n",
    "                center=0,\n",
    "                vmin=-1,\n",
    "                vmax=1,\n",
    "                square=True,\n",
    "                fmt='.2f',\n",
    "                linewidths=0.7,\n",
    "                cbar=True,\n",
    "                cbar_kws={\"shrink\": 0.685}\n",
    ")\n",
    "\n",
    "# Ajustando as labels na linha x\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.title('Mapa com 26 atributos', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicação da GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gerador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Gerador(nn.Module):\n",
    "    \"\"\"\n",
    "    O gerador recebe um vetor de entrada (contendo números aleatórios) e mapeia para o espaço de saída desejado, \n",
    "    produzindo um registro sintético.\n",
    "\n",
    "    Parâmetros:\n",
    "        - tamanho_entrada (int): O tamanho do vetor de entrada, que representa a dimensão do espaço latente.\n",
    "        - tamanho_saida (int): O tamanho do vetor de saída, que representa a dimensão do registro sintético.\n",
    "        - min_values (torch.Tensor): O tensor contendo os valores mínimos para cada coluna do dataframe original.\n",
    "        - max_values (torch.Tensor): O tensor contendo os valores máximos para cada coluna do dataframe original.\n",
    "        - coluna_indices (int): O índice da coluna que precisa ser ajustado para valores específicos.\n",
    "        - valores_possiveis (list): A lista de valores possíveis para a coluna específica.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tamanho_entrada, tamanho_saida, min_values, max_values, coluna_indices, valores_possiveis):\n",
    "        super(Gerador, self).__init__()\n",
    "        \n",
    "        # Definição da arquitetura do modelo\n",
    "        self.modelo = nn.Sequential(\n",
    "            nn.Linear(tamanho_entrada, 128), # Primeira camada de entrada (linear)\n",
    "            nn.ReLU(), # Capacitar não-linearidade\n",
    "            nn.Linear(128, tamanho_saida), # Segunda camada de saída\n",
    "            nn.Tanh() # Valores de saída no intervalo de (-1 e 1)\n",
    "        )\n",
    "        \n",
    "        self.min_values = min_values\n",
    "        self.max_values = max_values\n",
    "        self.coluna_indices = coluna_indices\n",
    "        self.valores_possiveis = torch.tensor(valores_possiveis)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Essa função passar os dados de entrada através do modelo. Recebe o tensor de entrada \"x (torch.Tensor)\" e retorna\n",
    "        o tensor de saída gerada pelo modelo. Em PyTorch, tensor são unidades básicas para trabalhar com redes neurais.\n",
    "\n",
    "        Parâmetros:\n",
    "            - x (torch.Tensor): O tensor de entrada.\n",
    "        \"\"\"\n",
    "        # Passa os dados pelo modelo\n",
    "        output = self.modelo(x)\n",
    "\n",
    "        # Restringe os valores gerados para estar dentro dos limites observados em cada coluna\n",
    "        output = (output + 1) * 0.5  # Mapeia para o intervalo (0, 1). Conforme está o DF normalizado\n",
    "        output = output * (self.max_values - self.min_values) + self.min_values\n",
    "        \n",
    "        # Ajustar os valores da coluna específica para os valores mais próximos na lista fornecida\n",
    "        output[:, self.coluna_indices] = self._ajustar_para_valores_possiveis(output[:, self.coluna_indices])\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def _ajustar_para_valores_possiveis(self, coluna_valores):\n",
    "        \"\"\"\n",
    "        Ajusta os valores da coluna para os valores mais próximos na lista de valores possíveis.\n",
    "\n",
    "        Parâmetros:\n",
    "            - coluna_valores (torch.Tensor): O tensor contendo os valores da coluna a serem ajustados.\n",
    "\n",
    "        Retorna:\n",
    "            - torch.Tensor: O tensor ajustado com os valores mais próximos na lista de valores possíveis.\n",
    "        \"\"\"\n",
    "        distancias = torch.abs(coluna_valores.unsqueeze(1) - self.valores_possiveis.unsqueeze(0))\n",
    "        indices_mais_proximos = torch.argmin(distancias, dim=1)\n",
    "        valores_ajustados = self.valores_possiveis[indices_mais_proximos]\n",
    "        return valores_ajustados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como funciona a arquitetura do `gerador`:\n",
    "\n",
    "1. O vetor de entrada é fornecido ao gerador, que é uma rede neural composta por camadas lineares.\n",
    "\n",
    "2. A primeira camada linear nn.Linear(tamanho_entrada, 128) mapeia o vetor de entrada para um vetor de características com 128 elementos. Cada elemento deste vetor representa a saída de um neurônio na camada oculta.\n",
    "\n",
    "3. Após a primeira camada linear, a função de ativação ReLU é aplicada a cada elemento do vetor de características. O que introduz não-linearidade na rede, visando que ela aprenda relações mais complexas nos dados.\n",
    "\n",
    "4. Em seguida, a segunda camada linear nn.Linear(128, tamanho_saida) mapeia o vetor de características para um vetor de saída com o tamanho especificado pelo parâmetro tamanho_saida. Cada elemento deste vetor representa uma componente da saída final do gerador.\n",
    "\n",
    "5. Por último, a função de ativação Tangente Hiperbólica (Tanh) é aplicada a cada elemento do vetor de saída, normalizando os valores de saída para o intervalo entre -1 e 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminador(nn.Module):\n",
    "    \"\"\"\n",
    "    Esta classe recebe um vetor de entrada (representando um registro) e produz uma única saída, \n",
    "    que representa a probabilidade do registro ser real.\n",
    "\n",
    "    Parâmetros:\n",
    "        - tamanho_entrada (int): O tamanho do vetor de entrada, que representa a dimensão do registro.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tamanho_entrada):\n",
    "        super(Discriminador, self).__init__()\n",
    "\n",
    "        # Definição da arquitetura do modelo\n",
    "        self.modelo = nn.Sequential(\n",
    "            nn.Linear(tamanho_entrada, 128), # Primeira camada de entrada (linear)\n",
    "            nn.ReLU(), # Capacitar não-linearidade\n",
    "            nn.Linear(128, 1), \n",
    "            nn.Sigmoid() # Saídas em (0 e 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Essa função passar os dados de entrada através do modelo. Recebe o tensor de entrada \"x (torch.Tensor)\" e retorna\n",
    "        o tensor de saída que da a probabilidade do registro ser real. \n",
    "        \n",
    "        Parâmetros:\n",
    "            - x (torch.Tensor): O tensor de entrada.\n",
    "        \"\"\"\n",
    "        return self.modelo(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como funciona a arquitetura do `discriminador`:\n",
    "\n",
    "1. O vetor de entrada, que representa um registro (real ou sintético), é fornecido ao discriminador.\n",
    "\n",
    "2. A primeira camada linear nn.Linear(tamanho_entrada, 128) mapeia o vetor de entrada para um vetor de características com 128 elementos. Cada elemento deste vetor representa a saída de um neurônio na camada oculta.\n",
    "\n",
    "3. Após a primeira camada linear, a função de ativação ReLU é aplicada a cada elemento do vetor de características. O que introduz não-linearidade na rede, visando que ela aprenda relações mais complexas nos dados.\n",
    "\n",
    "4. Em seguida, a segunda camada linear nn.Linear(128, 1) mapeia o vetor de características (após a aplicação da função ReLU) para uma única saída. Esta saída representa a probabilidade de o registro ser real.\n",
    "\n",
    "5. Por fim, a função de ativação Sigmoid é aplicada à saída da última camada linear, produzindo uma saída no intervalo entre 0 e 1, representando a probabilidade do registro ser real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Treinando o discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_discriminador(discriminador, otimizador, dados_reais, dados_falsos):\n",
    "    otimizador.zero_grad() # Zera os gradientes\n",
    "    previsao_real = discriminador(dados_reais) # Passando as 7 instâncias originais pro discriminador\n",
    "    perda_real = criterio(previsao_real, torch.ones_like(previsao_real)) # Próximo de 1 = verdadeiro, próximo de 0 = falso\n",
    "    perda_real.backward() # Algoritmo de backpropagation (Feed-Forward e Feed-Backward)\n",
    "\n",
    "    previsao_falsa = discriminador(dados_falsos)\n",
    "    perda_falsa = criterio(previsao_falsa, torch.zeros_like(previsao_falsa)) # Próximo de 0 = verdadeiro, próximo de 1 = falso\n",
    "    perda_falsa.backward()\n",
    "\n",
    "    otimizador.step() # Atualiza os gradientes\n",
    "\n",
    "    return perda_real + perda_falsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como funciona o treinamento do `discriminador`:\n",
    "1. otimizador.zero_grad(): necessário antes de calcular os gradientes para uma nova passagem de treinamento, caso contrário, os gradientes seriam acumulados.\n",
    "\n",
    "2. previsao_real = discriminador(dados_reais): Aqui, estamos passando os dados reais para o discriminador e obtendo as previsões dele.\n",
    "\n",
    "3. perda_real = criterio(previsao_real, torch.ones_like(previsao_real)): Calculamos a perda (ou erro) do discriminador em relação aos dados reais. Aqui, estamos comparando as previsões do discriminador com um tensor de uns (representando os rótulos \"verdadeiros\"). O objetivo é minimizar essa perda para que o discriminador seja capaz de distinguir corretamente os dados reais.\n",
    "\n",
    "4. perda_real.backward(): realiza a retropropagação (backpropagation). Aqui, os gradientes são calculados automaticamente para todos os tensores, sendo usados para atualizar os pesos da rede durante o próximo passo de otimização.\n",
    "    \n",
    "5. previsao_falsa = discriminador(dados_falsos): Agora, passamos os dados falsos (gerados pelo gerador) para o discriminador e obtemos as previsões dele.\n",
    "\n",
    "6. perda_falsa = criterio(previsao_falsa, torch.zeros_like(previsao_falsa)): Calculamos a perda do discriminador em relação aos dados falsos. Aqui, estamos comparando as previsões do discriminador com um tensor de zeros (representando os rótulos \"falsos\"). O objetivo é minimizar essa perda para que o discriminador seja capaz de distinguir corretamente os dados falsos.\n",
    "\n",
    "7. perda_falsa.backward(): Realizamos novamente o passo de retropropagação para calcular os gradientes e atualizar os pesos da rede com base na perda em relação aos dados falsos.\n",
    "\n",
    "8. otimizador.step(): Atualiza os parâmetros do discriminador com base nos gradientes calculados durante o passo de retropropagação. Isso é feito chamando o método step() do otimizador. Por isso, no começo utilizamos otimizador.zero_grad(),\n",
    "\n",
    "9. Por fim, retornamos a soma das perdas do discriminador em relação aos dados reais e falsos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Treinando o gerador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_gerador(gerador, otimizador, dados_falsos): # Etapa de duelo entre o gerador e o discriminador\n",
    "    otimizador.zero_grad()\n",
    "    previsao = discriminador(dados_falsos) \n",
    "    perda = criterio(previsao, torch.ones_like(previsao))\n",
    "    perda.backward()\n",
    "    otimizador.step()\n",
    "    return perda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como funciona o treinamento do `gerador`:\n",
    "1. otimizador.zero_grad(): necessário antes de calcular os gradientes para uma nova passagem de treinamento.\n",
    "\n",
    "2. previsao = discriminador(dados_falsos): Aqui, passamos os dados falsos (gerados pelo gerador) para o discriminador e obtemos as previsões dele. O objetivo do gerador é enganar o discriminador para que ele preveja que os dados falsos são reais.\n",
    "\n",
    "3. perda = criterio(previsao, torch.ones_like(previsao)): Calculamos a perda do gerador com base nas previsões do discriminador. Neste caso, estamos comparando as previsões do discriminador com um tensor de uns (representando os rótulos \"verdadeiros\"), mas do ponto de vista do gerador, ele quer que o discriminador pense que os dados falsos são reais. Portanto, o objetivo do gerador é minimizar essa perda.\n",
    "\n",
    "4. perda.backward(): Realizamos o passo de retropropagação para calcular os gradientes e atualizar os pesos do gerador com base na perda calculada.\n",
    "\n",
    "5. otimizador.step(): Atualiza os parâmetros do gerador com base nos gradientes calculados durante o passo de retropropagação.\n",
    "\n",
    "6. Por fim, retornamos a perda do gerador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Função de normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar(df): # Garante que os dados estejam no intervalo de (0 e 1)\n",
    "    return (df - df.min()) / (df.max() - df.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Função de desnormalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desnormalizar(df, df_normalizado): # Retorna os valores ao original\n",
    "    return df_normalizado * (df.max() - df.min()) + df.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalizado = normalizar(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definindo dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanho_entrada = len(df.columns)  # Aplica em todas as colunas da base de dados (24)\n",
    "tamanho_saida = tamanho_entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ajuste de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_epocas = 10000 # Quantidade de iterações em cima da base\n",
    "tamanho_batch = 128 # Dados divididos em lotes\n",
    "\n",
    "taxa_aprendizado = 0.00001\n",
    "quantidade_novos_registros = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_min_max(df):\n",
    "    \"\"\"\n",
    "    Calcula os valores mínimos e máximos de cada coluna do dataframe.\n",
    "\n",
    "    Parâmetros:\n",
    "        - df (pandas.DataFrame): O dataframe contendo os dados.\n",
    "\n",
    "    Retorna:\n",
    "        - min_values (torch.Tensor): O tensor contendo os valores mínimos para cada coluna.\n",
    "        - max_values (torch.Tensor): O tensor contendo os valores máximos para cada coluna.\n",
    "    \"\"\"\n",
    "    min_values = torch.tensor(df.min().values, dtype=torch.float32)\n",
    "    max_values = torch.tensor(df.max().values, dtype=torch.float32)\n",
    "    return min_values, max_values\n",
    "\n",
    "min_values, max_values = calcular_min_max(df_normalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalizado.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando o gerador e o discriminador\n",
    "gerador = Gerador(tamanho_entrada, tamanho_saida, min_values, max_values, 4, [0, 1])\n",
    "discriminador = Discriminador(tamanho_entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a função de perda\n",
    "criterio = nn.BCELoss() # Entropia cruzada para casos binários\n",
    "\n",
    "# Definindo os otimizadores\n",
    "otimizador_gerador = optim.Adam(gerador.parameters(), lr=taxa_aprendizado) # Estava usando antes o (SGD)\n",
    "otimizador_discriminador = optim.Adam(discriminador.parameters(), lr=taxa_aprendizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Treinando a GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoca in range(numero_epocas):\n",
    "    for i in range(0, len(df_normalizado), tamanho_batch):\n",
    "        # Colocando os dados reais no formato que o PyTorch interpreta\n",
    "        dados_reais = torch.tensor(df_normalizado.iloc[i:i+tamanho_batch].values, dtype=torch.float32)\n",
    "        \n",
    "        # Dados falsos feitos pelo Gerador\n",
    "        ruido = torch.randn(tamanho_batch, tamanho_entrada)\n",
    "        dados_falsos = gerador(ruido)\n",
    "\n",
    "        # Treinando o Discriminador\n",
    "        perda_discriminador = treinar_discriminador(discriminador, otimizador_discriminador, dados_reais, dados_falsos)\n",
    "\n",
    "        # Treinando o Gerador\n",
    "        ruido = torch.randn(tamanho_batch, tamanho_entrada)\n",
    "        dados_falsos = gerador(ruido)\n",
    "        perda_gerador = treinar_gerador(gerador, otimizador_gerador, dados_falsos)\n",
    "\n",
    "    # Imprimir progresso a cada 100 épocas\n",
    "    if (epoca+1) % 100 == 0:\n",
    "        print(f\"Época [{epoca+1}/{numero_epocas}], Perda do Discriminador: {perda_discriminador.item()}, Perda do Gerador: {perda_gerador.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gerando dados sintéticos e aplicando restrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar dados sintéticos para toda a base de dados\n",
    "novos_registros = []\n",
    "for _ in range(quantidade_novos_registros // tamanho_batch):\n",
    "    ruido = torch.randn(tamanho_batch, tamanho_entrada)\n",
    "    batch_sintetico = gerador(ruido).detach().numpy()\n",
    "\n",
    "    novos_registros.append(batch_sintetico)\n",
    "\n",
    "\n",
    "# Quando o número de dados gerados não é múltiplo do tamanho do batch\n",
    "dados_restantes = quantidade_novos_registros % tamanho_batch\n",
    "if dados_restantes > 0:\n",
    "    ruido = torch.randn(dados_restantes, tamanho_entrada)\n",
    "    batch_sintetico = gerador(ruido).detach().numpy()\n",
    "    \n",
    "    # Restrição 1: Valores negativos iguais a zero\n",
    "    batch_sintetico[batch_sintetico < 0] = 0\n",
    "\n",
    "    novos_registros.append(batch_sintetico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Desnormalizando e salvando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novos_registros = np.concatenate(novos_registros)\n",
    "novos_registros = desnormalizar(df, pd.DataFrame(novos_registros, columns=df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novos_registros.to_csv('../dados/registros_gan.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novos_registros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_correlacao = df.corr()\n",
    "\n",
    "# Plotando o gráfico\n",
    "plt.figure(figsize=(16, 16), facecolor='#eaeaf2')\n",
    "\n",
    "ax = sns.heatmap(data=matriz_correlacao,\n",
    "                xticklabels=df.columns,\n",
    "                yticklabels=df.columns,\n",
    "                annot=True, \n",
    "                cmap='coolwarm',\n",
    "                center=0,\n",
    "                vmin=-1,\n",
    "                vmax=1,\n",
    "                square=True,\n",
    "                fmt='.2f',\n",
    "                linewidths=0.7,\n",
    "                cbar=True,\n",
    "                cbar_kws={\"shrink\": 0.685} \n",
    "\n",
    ")\n",
    "\n",
    "# Ajustando as labels na linha x\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# título e apresentação do gráfico\n",
    "plt.title('Mapa de calor da base original (7 instâncias)', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gan = pd.read_csv(\"../dados/registros_gan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_correlacao_gan = df_gan.corr()\n",
    "\n",
    "# Plotando o gráfico\n",
    "plt.figure(figsize=(16, 16), facecolor='#eaeaf2')\n",
    "\n",
    "ax = sns.heatmap(data=matriz_correlacao_gan,\n",
    "                xticklabels=df.columns,\n",
    "                yticklabels=df.columns,\n",
    "                annot=True, \n",
    "                cmap='coolwarm',\n",
    "                center=0,\n",
    "                vmin=-1,\n",
    "                vmax=1,\n",
    "                square=True,\n",
    "                fmt='.2f',\n",
    "                linewidths=0.7,\n",
    "                cbar=True,\n",
    "                cbar_kws={\"shrink\": 0.685} \n",
    "\n",
    ")\n",
    "\n",
    "# Ajustando as labels na linha x\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# título e apresentação do gráfico\n",
    "plt.title('Mapa de calor na base gerada pelo GAN', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### formatando os resultados do novo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Função para transformar os dados e padronizar conforme o original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforma_int(coluna):\n",
    "    return int(coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforma_float(column):\n",
    "    return round(float(column), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapear_0_ou_1(valor):\n",
    "    if valor <= 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapear_type_of_production(valor):\n",
    "    if valor <= 1.5:\n",
    "        return 1\n",
    "    elif valor <= 2.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separando as colunas para os tipos de transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gan.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_float = ['height_of_jacket_or_sub-structure (m)', 'height_of_jacket_or_sub-structure (m)', 'risk_to_personnel-complete', 'risk_to_personnel-partial', 'technical_feasibility_or_challenge-complete', 'technical_feasibility_or_challenge-partial', 'commercial_impact_on_fisheries-complete', 'commercial_impact_on_fisheries-partial', 'wider_community_impact-complete', 'wider_community_impact-partial', 'total_removal_cost-complete', 'total_removal_cost-partial', 'impacts_of_option-complete']\n",
    "colunas_int = ['water_depth (m)', 'installation_date', 'weight (t)', 'number_of_legs', 'number_of_piles', 'distance_to_coast (km)', 'energy_consumption-complete (GJ)', 'energy_consumption-partial (GJ)', 'emissions-complete (t)', 'emissions-partial (t)']\n",
    "coluna_mapear_0_ou_1 = ['risk_to_other_users-complete', 'impacts_of_option-partial']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBS:** A coluna `risk_to_other_users-partial` contém diferentes tamanhos de valores float, como 2.3 x 10<sup>-5</sup> ou 7.8 x 10<sup>-8</sup>. Portanto, não será formatada conforme as demais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aplicando as transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando as transformações às colunas específicas\n",
    "df_gan['risk_to_other_users-complete'] = df_gan['risk_to_other_users-complete'].apply(mapear_0_ou_1)\n",
    "df_gan['impacts_of_option-partial'] = df_gan['impacts_of_option-partial'].apply(mapear_0_ou_1)\n",
    "df_gan['type_of_production (1 oil and gas; 2 oil; 3 gas)'] = df_gan['type_of_production (1 oil and gas; 2 oil; 3 gas)'].apply(mapear_type_of_production)\n",
    "\n",
    "for coluna in colunas_float:\n",
    "    df_gan[coluna] = df_gan[coluna].apply(transforma_float)\n",
    "\n",
    "for coluna in colunas_int:\n",
    "    df_gan[coluna] = df_gan[coluna].apply(transforma_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações para exibição do DataFrame\n",
    "pd.set_option('display.max_columns', None)  # Mostrar todas as colunas\n",
    "pd.set_option('display.max_rows', None)     # Mostrar todas as linhas\n",
    "pd.set_option('display.max_colwidth', None) # Mostrar todo o conteúdo das células\n",
    "\n",
    "\n",
    "df_gan.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gan.to_csv('../dados/registros_gan.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
